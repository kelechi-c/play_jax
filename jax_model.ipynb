{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import jax\n",
    "import numpy as np \n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx, linen as lnn\n",
    "from flax.training import train_state\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 200\n",
    "batch_size = 32\n",
    "learn_rate = 0.01\n",
    "epochs = 30\n",
    "data_dir = '/kaggle/input/plantvillage-dataset/color'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(200, 200),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(200, 200),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(lnn.module):\n",
    "\n",
    "    @lnn.compact\n",
    "    def __call__(self, img):\n",
    "        x = lnn.Conv(features=32, kernel_size=(3, 3))(img)\n",
    "        x = lnn.relu(x)\n",
    "        x = lnn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = lnn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = lnn.relu(x)\n",
    "        x = lnn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = lnn.Dense(features=256)(x)\n",
    "        x = lnn.relu(x)\n",
    "        x = lnn.Dense(features=10)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(*, logits, labels):\n",
    "    encoded_labels = jax.nn.one_hot(labels, num_classes=38)\n",
    "    ce_loss = optax.softmax_cross_entropy(logits=logits, labels=encoded_labels)\n",
    "\n",
    "    return ce_loss.mean()\n",
    "\n",
    "\n",
    "def compute_model_metrics(*, logits, labels):\n",
    "    loss = cross_entropy(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "\n",
    "    metrics = {\"loss\": loss, \"accuracy\": accuracy}\n",
    "\n",
    "    return metrics    \n",
    "\n",
    "\n",
    "def compute_loss(params, images, labels):\n",
    "    logits = Convnet().apply({\"params\": params}, images)\n",
    "    loss = cross_entropy(logits, labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def init_train_state(rng, lr=learn_rate):\n",
    "    convnet = Convnet()\n",
    "    params = convnet.init(rng, jnp.ones([1, image_size, image_size, 3]))['params']\n",
    "    tx = optax.adam(learning_rate=lr)\n",
    "    \n",
    "    train_state = train_state.TrainState.create(apply_fn=convnet.apply, params=params, tx=tx)\n",
    "    \n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    images, labels = batch\n",
    "    (_, logits), grads = jax.value_and_grad(compute_loss, has_aux=True)(state.params, images, labels)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_model_metrics(logits=logits, labels=labels)\n",
    "    \n",
    "    return state, metrics\n",
    "    \n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    images, labels = batch\n",
    "    logits = Convnet().apply({'params': state.params}, images)\n",
    "    \n",
    "    return compute_model_metrics(logits=logits, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(state, batch):\n",
    "    test_imgs, test_labels = batch\n",
    "    metrics = eval_step(state, test_imgs, test_labels)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    metrics = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "lr = 1e-5\n",
    "seed = 0\n",
    "\n",
    "state = init_train_state(init_rng, lr)\n",
    "\n",
    "train_loss, test_loss = [], []\n",
    "train_acc, test_acc = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf_convnet(state, train_loader, test_loader, num_epochs=epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_batch_loss, train_batch_accuracy = [], []\n",
    "        val_batch_loss, val_batch_accuracy = [], []\n",
    "        \n",
    "        for train_batch in train_loader:\n",
    "            state, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
